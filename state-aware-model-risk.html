<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>State-Aware Model Risk Visualization | Hannah Attar</title>

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap" rel="stylesheet">

  <link rel="stylesheet" href="styles.css" />
</head>
<body>

  <!-- Top navigation -->
  <div class="topbar">
    <div class="topbar-inner">
      <a class="site-title" href="index.html">Hannah Attar</a>
      <div class="topnav">
        <a href="projects.html">Projects</a>
        <a href="experience.html">Experience</a>
        <a href="Attar_Resume_2025.pdf" target="_blank" rel="noopener">Resume</a>
      </div>
    </div>
  </div>

  <div class="detail">
    <a class="detail-back" href="projects.html">← Back to Projects</a>

    <header class="detail-hero">
      <div class="detail-kicker">Project Report</div>
      <h1 class="detail-title">State-Aware Model Risk Visualization</h1>
      <p class="detail-subtitle">
        Diagnosing how decision geometry and confidence reliability shift across volatility-driven market conditions (SPY, daily).
      </p>

      <div class="detail-meta">
        <div><span>Author:</span> Hannah Attar</div>
        <div><span>Model:</span> Logistic Regression (global vs state-specific)</div>
        <div><span>States:</span> Low-vol (bottom 20%), High-vol (top 20%) by 20-day realized volatility</div>
        <div><span>Task:</span> Predict next-day direction (return &gt; 0)</div>
      </div>

      <div class="detail-actions">
        <a class="btn" href="#" target="_blank" rel="noopener">GitHub →</a>
        <a class="btn" href="project_state_aware/state_aware_model_risk_report.pdf" target="_blank" rel="noopener">Download PDF →</a>
      </div>
    </header>

    <section class="detail-section">
      <h2>Abstract</h2>
      <p>
        Financial time series are nonstationary, and models trained on pooled data can appear stable on average while failing in specific
        market conditions. This project is a visualization-first diagnostic study of model risk across volatility-defined states.
        Using daily SPY features, we train a global logistic regression model and two state-specific models, then compare
        (i) decision boundaries in the feature plane, (ii) where state-specific models disagree most, and (iii) whether confidence remains
        informative when volatility is elevated. The goal is not alpha, but identifying where a “reasonable-looking” model becomes
        confidently wrong.
      </p>

      <div class="callout">
        <div class="callout-title">TL;DR Highlights</div>
        <ul>
          <li>Trained a global model + two state-specific models (low-vol vs high-vol) using identical model class.</li>
          <li>Visualized how decision boundaries shift across market conditions in the (ret5, vol20) plane.</li>
          <li>Mapped where state-specific probability predictions disagree most.</li>
          <li>Evaluated confidence reliability by comparing accuracy vs confidence deciles across states.</li>
        </ul>
      </div>
    </section>

    <section class="detail-section">
      <h2>Overview</h2>
      <p>
        This project treats volatility as a proxy for market “condition” and asks a simple question:
        does the same model behave the same way when volatility is low versus high?
        If not, the mismatch shows up as boundary shifts, disagreement regions, and confidence breakdown.
      </p>

      <div class="grid-2">
        <div class="card">
          <div class="card-title">Inputs</div>
          <ul class="tight">
            <li><strong>ret1</strong>: 1-day return</li>
            <li><strong>ret5</strong>: 5-day cumulative return</li>
            <li><strong>vol20</strong>: 20-day realized volatility (rolling std of returns)</li>
          </ul>
        </div>

        <div class="card">
          <div class="card-title">Output</div>
          <ul class="tight">
            <li><strong>y<sub>t</sub> = 1</strong> if next-day return &gt; 0</li>
            <li>Logistic probability <strong>P(y=1 | x)</strong></li>
            <li>Decision boundary at <strong>P=0.5</strong></li>
          </ul>
        </div>
      </div>
    </section>

    <section class="detail-section">
      <h2>Method</h2>
      <div class="grid-2">
        <div class="card">
          <div class="card-title">State definition</div>
          <p class="muted">
            Use empirical quantiles of vol20.
          </p>
          <ul class="tight">
            <li><strong>Low-vol state:</strong> bottom 20% of vol20</li>
            <li><strong>High-vol state:</strong> top 20% of vol20</li>
            <li><strong>Middle 60%:</strong> treated as neutral (not used in extreme comparisons)</li>
          </ul>
        </div>

        <div class="card">
          <div class="card-title">Models</div>
          <p class="muted">
            Same model class everywhere to isolate data differences.
          </p>
          <ul class="tight">
            <li><strong>Global:</strong> trained on all data</li>
            <li><strong>Low-vol:</strong> trained only on low-vol observations</li>
            <li><strong>High-vol:</strong> trained only on high-vol observations</li>
          </ul>
        </div>
      </div>

      <div class="card" style="margin-top:14px;">
        <div class="card-title">What “model risk” means here</div>
        <p class="muted" style="margin:0;">
          If the model’s probability beliefs and boundary geometry depend on state, then a single global model can be a compromise that looks
          fine on average but behaves inconsistently in the conditions you care about most (stress). Confidence can also become unreliable,
          producing overconfident errors exactly when stakes are higher.
        </p>
      </div>
    </section>

    <section class="detail-section">
      <h2>Results</h2>

      <figure class="figure">
        <figcaption class="figcap">
          <strong>Figure 1.</strong> Decision boundary shift across market conditions (global vs low-vol vs high-vol).
          Same model class, different learned geometry.
        </figcaption>
        <img class="figimg" src="project_state_aware/figs/fig_1_decision_boundaries.png" alt="Decision boundaries across market conditions">
      </figure>

      <figure class="figure">
        <figcaption class="figcap">
          <strong>Figure 2.</strong> Where state-specific models disagree most: heatmap of |P(high) − P(low)|.
        </figcaption>
        <img class="figimg" src="project_state_aware/figs/fig_2_regime_disagreement.png" alt="State model disagreement heatmap">
      </figure>

      <figure class="figure">
        <figcaption class="figcap">
          <strong>Figure 3.</strong> Confidence vs accuracy for the global model, split by state.
          Confidence is less reliable in high-vol conditions.
        </figcaption>
        <img class="figimg" src="project_state_aware/figs/fig_3_confidence_vs_accuracy.png" alt="Accuracy vs confidence by state">
      </figure>

      <div class="callout">
        <div class="callout-title">Key takeaways</div>
        <ul>
          <li><strong>Geometry shifts:</strong> the boundary changes across market conditions, meaning the feature tradeoff changes with volatility.</li>
          <li><strong>Disagreement concentrates:</strong> the largest belief differences occur in regions associated with stress conditions.</li>
          <li><strong>Confidence breaks:</strong> high confidence does not consistently imply high accuracy in high-vol periods.</li>
        </ul>
      </div>
    </section>

    <section class="detail-section">
      <h2>Reproducibility</h2>
      <div class="card">
        <div class="card-title">How to run</div>
        <ol class="tight">
          <li>Install requirements (scikit-learn, pandas, numpy, matplotlib).</li>
          <li>Run training script to fit global / low-vol / high-vol pipelines.</li>
          <li>Run plotting script to generate the three diagnostic figures.</li>
        </ol>
        <p class="muted" style="margin:10px 0 0;">
          If you want this section to be exact, paste your repo file names (train script + plot script) and I’ll lock it to your structure.
        </p>
      </div>
    </section>

    <div class="footer">
      © <span id="y"></span> Hannah Attar
    </div>
  </div>

  <script>
    const y = document.getElementById("y");
    if (y) y.textContent = new Date().getFullYear();
  </script>

</body>
</html>
